{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d40f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9733dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test_splits(train_size, batch_size=1):\n",
    "    # We prefetch with a buffer the same size as the dataset because th dataset\n",
    "    # is very small and fits into memory.\n",
    "    dataset = (\n",
    "        tfds.load(name=\"wine_quality\", as_supervised=True, split=\"train\")\n",
    "        .map(lambda x, y: (x, tf.cast(y, tf.float32)))\n",
    "        .prefetch(buffer_size=dataset_size)\n",
    "        .cache()\n",
    "    )\n",
    "    # We shuffle with a buffer the same size as the dataset.\n",
    "    train_dataset = (\n",
    "        dataset.take(train_size).shuffle(buffer_size=train_size).batch(batch_size)\n",
    "    )\n",
    "    test_dataset = dataset.skip(train_size).batch(batch_size)\n",
    "\n",
    "    return train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5426481",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_units = [8, 8]\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "def run_experiment(model, loss, train_dataset, test_dataset):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(learning_rate=learning_rate),\n",
    "        loss=loss,\n",
    "        metrics=[keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    model.fit(train_dataset, epochs=num_epochs, validation_data=test_dataset)\n",
    "    print(\"Model training finished.\")\n",
    "    _, rmse = model.evaluate(train_dataset, verbose=0)\n",
    "    print(f\"Train RMSE: {round(rmse, 3)}\")\n",
    "\n",
    "    print(\"Evaluating model performance...\")\n",
    "    _, rmse = model.evaluate(test_dataset, verbose=0)\n",
    "    print(f\"Test RMSE: {round(rmse, 3)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0ee19d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAMES = [\n",
    "    \"fixed acidity\",\n",
    "    \"volatile acidity\",\n",
    "    \"citric acid\",\n",
    "    \"residual sugar\",\n",
    "    \"chlorides\",\n",
    "    \"free sulfur dioxide\",\n",
    "    \"total sulfur dioxide\",\n",
    "    \"density\",\n",
    "    \"pH\",\n",
    "    \"sulphates\",\n",
    "    \"alcohol\",\n",
    "]\n",
    "\n",
    "\n",
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        inputs[feature_name] = layers.Input(\n",
    "            name=feature_name, shape=(1,), dtype=tf.float32\n",
    "        )\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d537d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_model():\n",
    "    inputs = create_model_inputs()\n",
    "    input_values = [value for _, value in sorted(inputs.items())]\n",
    "    features = keras.layers.concatenate(input_values)\n",
    "    features = layers.BatchNormalization()(features)\n",
    "\n",
    "    # Create hidden layers with deterministic weights using the Dense layer.\n",
    "    for units in hidden_units:\n",
    "        features = layers.Dense(units, activation=\"sigmoid\")(features)\n",
    "    # The output is deterministic: a single point estimate.\n",
    "    outputs = layers.Dense(units=1)(features)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c681213a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fixed acidity': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'fixed acidity')>,\n",
       " 'volatile acidity': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'volatile acidity')>,\n",
       " 'citric acid': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'citric acid')>,\n",
       " 'residual sugar': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'residual sugar')>,\n",
       " 'chlorides': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'chlorides')>,\n",
       " 'free sulfur dioxide': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'free sulfur dioxide')>,\n",
       " 'total sulfur dioxide': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'total sulfur dioxide')>,\n",
       " 'density': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'density')>,\n",
       " 'pH': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'pH')>,\n",
       " 'sulphates': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'sulphates')>,\n",
       " 'alcohol': <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'alcohol')>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_model_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcba5494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\lomp\\tensorflow_datasets\\wine_quality\\white\\1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6bdfc7327244b68fc209a9f813c684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7410c02cb3f446db8005e08c81505ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\lomp\\tensorflow_datasets\\wine_quality\\white\\1.0.0.incompleteHJS9ZT\\wine_quality-train.tfrecâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset wine_quality downloaded and prepared to C:\\Users\\lomp\\tensorflow_datasets\\wine_quality\\white\\1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 4898\n",
    "batch_size = 256\n",
    "train_size = int(dataset_size * 0.85)\n",
    "train_dataset, test_dataset = get_train_and_test_splits(train_size, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a356e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/100\n",
      "17/17 [==============================] - 2s 21ms/step - loss: 31.4088 - root_mean_squared_error: 5.6044 - val_loss: 32.3489 - val_root_mean_squared_error: 5.6876\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 29.1470 - root_mean_squared_error: 5.3988 - val_loss: 30.0166 - val_root_mean_squared_error: 5.4787\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 27.2400 - root_mean_squared_error: 5.2192 - val_loss: 27.6756 - val_root_mean_squared_error: 5.2608\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 25.4189 - root_mean_squared_error: 5.0417 - val_loss: 25.4382 - val_root_mean_squared_error: 5.0436\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 23.6594 - root_mean_squared_error: 4.8641 - val_loss: 23.3411 - val_root_mean_squared_error: 4.8313\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 21.9578 - root_mean_squared_error: 4.6859 - val_loss: 21.3769 - val_root_mean_squared_error: 4.6235\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 20.3150 - root_mean_squared_error: 4.5072 - val_loss: 19.5367 - val_root_mean_squared_error: 4.4200\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 18.7326 - root_mean_squared_error: 4.3281 - val_loss: 17.8023 - val_root_mean_squared_error: 4.2193\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 17.2099 - root_mean_squared_error: 4.1485 - val_loss: 16.1753 - val_root_mean_squared_error: 4.0219\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 15.7484 - root_mean_squared_error: 3.9684 - val_loss: 14.6557 - val_root_mean_squared_error: 3.8283\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 14.3519 - root_mean_squared_error: 3.7884 - val_loss: 13.2403 - val_root_mean_squared_error: 3.6387\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 13.0241 - root_mean_squared_error: 3.6089 - val_loss: 11.9224 - val_root_mean_squared_error: 3.4529\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 11.7626 - root_mean_squared_error: 3.4297 - val_loss: 10.6942 - val_root_mean_squared_error: 3.2702\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 10.5715 - root_mean_squared_error: 3.2514 - val_loss: 9.5453 - val_root_mean_squared_error: 3.0895\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 9.4441 - root_mean_squared_error: 3.0731 - val_loss: 8.4764 - val_root_mean_squared_error: 2.9114\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 8.3914 - root_mean_squared_error: 2.8968 - val_loss: 7.4917 - val_root_mean_squared_error: 2.7371\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 7.4155 - root_mean_squared_error: 2.7231 - val_loss: 6.5820 - val_root_mean_squared_error: 2.5655\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 6.5115 - root_mean_squared_error: 2.5518 - val_loss: 5.7580 - val_root_mean_squared_error: 2.3996\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 5.6859 - root_mean_squared_error: 2.3845 - val_loss: 5.0021 - val_root_mean_squared_error: 2.2365\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.9328 - root_mean_squared_error: 2.2210 - val_loss: 4.3249 - val_root_mean_squared_error: 2.0796\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 4.2555 - root_mean_squared_error: 2.0629 - val_loss: 3.7164 - val_root_mean_squared_error: 1.9278\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 3.6473 - root_mean_squared_error: 1.9098 - val_loss: 3.1807 - val_root_mean_squared_error: 1.7834\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 3.1101 - root_mean_squared_error: 1.7635 - val_loss: 2.7051 - val_root_mean_squared_error: 1.6447\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.6391 - root_mean_squared_error: 1.6245 - val_loss: 2.2940 - val_root_mean_squared_error: 1.5146\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 2.2308 - root_mean_squared_error: 1.4936 - val_loss: 1.9408 - val_root_mean_squared_error: 1.3931\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.8830 - root_mean_squared_error: 1.3722 - val_loss: 1.6455 - val_root_mean_squared_error: 1.2828\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.5894 - root_mean_squared_error: 1.2607 - val_loss: 1.3983 - val_root_mean_squared_error: 1.1825\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 1.3473 - root_mean_squared_error: 1.1607 - val_loss: 1.1966 - val_root_mean_squared_error: 1.0939\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.1536 - root_mean_squared_error: 1.0740 - val_loss: 1.0447 - val_root_mean_squared_error: 1.0221\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 1.0059 - root_mean_squared_error: 1.0029 - val_loss: 0.9315 - val_root_mean_squared_error: 0.9651\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8981 - root_mean_squared_error: 0.9477 - val_loss: 0.8548 - val_root_mean_squared_error: 0.9245\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.8263 - root_mean_squared_error: 0.9090 - val_loss: 0.8084 - val_root_mean_squared_error: 0.8991\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7832 - root_mean_squared_error: 0.8850 - val_loss: 0.7856 - val_root_mean_squared_error: 0.8863\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7597 - root_mean_squared_error: 0.8716 - val_loss: 0.7764 - val_root_mean_squared_error: 0.8811\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7500 - root_mean_squared_error: 0.8660 - val_loss: 0.7722 - val_root_mean_squared_error: 0.8788\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7447 - root_mean_squared_error: 0.8630 - val_loss: 0.7685 - val_root_mean_squared_error: 0.8767\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7392 - root_mean_squared_error: 0.8598 - val_loss: 0.7617 - val_root_mean_squared_error: 0.8728\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.7344 - root_mean_squared_error: 0.8570 - val_loss: 0.7545 - val_root_mean_squared_error: 0.8686\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.7291 - root_mean_squared_error: 0.8539 - val_loss: 0.7496 - val_root_mean_squared_error: 0.8658\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7237 - root_mean_squared_error: 0.8507 - val_loss: 0.7422 - val_root_mean_squared_error: 0.8615\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7179 - root_mean_squared_error: 0.8473 - val_loss: 0.7344 - val_root_mean_squared_error: 0.8570\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7144 - root_mean_squared_error: 0.8452 - val_loss: 0.7282 - val_root_mean_squared_error: 0.8533\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7088 - root_mean_squared_error: 0.8419 - val_loss: 0.7220 - val_root_mean_squared_error: 0.8497\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7025 - root_mean_squared_error: 0.8382 - val_loss: 0.7149 - val_root_mean_squared_error: 0.8455\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6979 - root_mean_squared_error: 0.8354 - val_loss: 0.7063 - val_root_mean_squared_error: 0.8404\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6926 - root_mean_squared_error: 0.8322 - val_loss: 0.6996 - val_root_mean_squared_error: 0.8364\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6875 - root_mean_squared_error: 0.8291 - val_loss: 0.6932 - val_root_mean_squared_error: 0.8326\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6820 - root_mean_squared_error: 0.8258 - val_loss: 0.6889 - val_root_mean_squared_error: 0.8300\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6768 - root_mean_squared_error: 0.8227 - val_loss: 0.6803 - val_root_mean_squared_error: 0.8248\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6727 - root_mean_squared_error: 0.8202 - val_loss: 0.6745 - val_root_mean_squared_error: 0.8213\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6662 - root_mean_squared_error: 0.8162 - val_loss: 0.6692 - val_root_mean_squared_error: 0.8181\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6622 - root_mean_squared_error: 0.8138 - val_loss: 0.6639 - val_root_mean_squared_error: 0.8148\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6559 - root_mean_squared_error: 0.8099 - val_loss: 0.6591 - val_root_mean_squared_error: 0.8118\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6508 - root_mean_squared_error: 0.8067 - val_loss: 0.6485 - val_root_mean_squared_error: 0.8053\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6467 - root_mean_squared_error: 0.8042 - val_loss: 0.6450 - val_root_mean_squared_error: 0.8031\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6409 - root_mean_squared_error: 0.8005 - val_loss: 0.6383 - val_root_mean_squared_error: 0.7989\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6377 - root_mean_squared_error: 0.7985 - val_loss: 0.6335 - val_root_mean_squared_error: 0.7959\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6332 - root_mean_squared_error: 0.7957 - val_loss: 0.6280 - val_root_mean_squared_error: 0.7925\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6284 - root_mean_squared_error: 0.7927 - val_loss: 0.6230 - val_root_mean_squared_error: 0.7893\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6244 - root_mean_squared_error: 0.7902 - val_loss: 0.6201 - val_root_mean_squared_error: 0.7875\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6206 - root_mean_squared_error: 0.7878 - val_loss: 0.6154 - val_root_mean_squared_error: 0.7845\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6191 - root_mean_squared_error: 0.7868 - val_loss: 0.6127 - val_root_mean_squared_error: 0.7828\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6128 - root_mean_squared_error: 0.7828 - val_loss: 0.6078 - val_root_mean_squared_error: 0.7796\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6089 - root_mean_squared_error: 0.7803 - val_loss: 0.6023 - val_root_mean_squared_error: 0.7761\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.6072 - root_mean_squared_error: 0.7792 - val_loss: 0.6010 - val_root_mean_squared_error: 0.7753\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6024 - root_mean_squared_error: 0.7761 - val_loss: 0.5961 - val_root_mean_squared_error: 0.7721\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.6003 - root_mean_squared_error: 0.7748 - val_loss: 0.5929 - val_root_mean_squared_error: 0.7700\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5976 - root_mean_squared_error: 0.7731 - val_loss: 0.5910 - val_root_mean_squared_error: 0.7688\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5924 - root_mean_squared_error: 0.7697 - val_loss: 0.5873 - val_root_mean_squared_error: 0.7664\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5921 - root_mean_squared_error: 0.7695 - val_loss: 0.5892 - val_root_mean_squared_error: 0.7676\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5908 - root_mean_squared_error: 0.7686 - val_loss: 0.5827 - val_root_mean_squared_error: 0.7634\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5878 - root_mean_squared_error: 0.7667 - val_loss: 0.5815 - val_root_mean_squared_error: 0.7626\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5860 - root_mean_squared_error: 0.7655 - val_loss: 0.5800 - val_root_mean_squared_error: 0.7616\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5844 - root_mean_squared_error: 0.7644 - val_loss: 0.5787 - val_root_mean_squared_error: 0.7607\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5828 - root_mean_squared_error: 0.7634 - val_loss: 0.5774 - val_root_mean_squared_error: 0.7599\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5824 - root_mean_squared_error: 0.7631 - val_loss: 0.5760 - val_root_mean_squared_error: 0.7589\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5798 - root_mean_squared_error: 0.7614 - val_loss: 0.5754 - val_root_mean_squared_error: 0.7586\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5801 - root_mean_squared_error: 0.7617 - val_loss: 0.5741 - val_root_mean_squared_error: 0.7577\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5783 - root_mean_squared_error: 0.7604 - val_loss: 0.5731 - val_root_mean_squared_error: 0.7571\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5751 - root_mean_squared_error: 0.7583 - val_loss: 0.5732 - val_root_mean_squared_error: 0.7571\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5767 - root_mean_squared_error: 0.7594 - val_loss: 0.5714 - val_root_mean_squared_error: 0.7559\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5757 - root_mean_squared_error: 0.7588 - val_loss: 0.5708 - val_root_mean_squared_error: 0.7555\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5753 - root_mean_squared_error: 0.7585 - val_loss: 0.5702 - val_root_mean_squared_error: 0.7551\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5746 - root_mean_squared_error: 0.7580 - val_loss: 0.5695 - val_root_mean_squared_error: 0.7546\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5732 - root_mean_squared_error: 0.7571 - val_loss: 0.5687 - val_root_mean_squared_error: 0.7541\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5738 - root_mean_squared_error: 0.7575 - val_loss: 0.5679 - val_root_mean_squared_error: 0.7536\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5725 - root_mean_squared_error: 0.7566 - val_loss: 0.5674 - val_root_mean_squared_error: 0.7532\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5710 - root_mean_squared_error: 0.7557 - val_loss: 0.5675 - val_root_mean_squared_error: 0.7533\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5700 - root_mean_squared_error: 0.7550 - val_loss: 0.5663 - val_root_mean_squared_error: 0.7525\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5706 - root_mean_squared_error: 0.7554 - val_loss: 0.5663 - val_root_mean_squared_error: 0.7526\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5702 - root_mean_squared_error: 0.7551 - val_loss: 0.5650 - val_root_mean_squared_error: 0.7516\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5682 - root_mean_squared_error: 0.7538 - val_loss: 0.5647 - val_root_mean_squared_error: 0.7514\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5675 - root_mean_squared_error: 0.7534 - val_loss: 0.5639 - val_root_mean_squared_error: 0.7509\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5679 - root_mean_squared_error: 0.7536 - val_loss: 0.5640 - val_root_mean_squared_error: 0.7510\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5685 - root_mean_squared_error: 0.7540 - val_loss: 0.5625 - val_root_mean_squared_error: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5663 - root_mean_squared_error: 0.7526 - val_loss: 0.5631 - val_root_mean_squared_error: 0.7504\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5681 - root_mean_squared_error: 0.7537 - val_loss: 0.5613 - val_root_mean_squared_error: 0.7492\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5653 - root_mean_squared_error: 0.7519 - val_loss: 0.5608 - val_root_mean_squared_error: 0.7489\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5644 - root_mean_squared_error: 0.7513 - val_loss: 0.5603 - val_root_mean_squared_error: 0.7485\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.5677 - root_mean_squared_error: 0.7534 - val_loss: 0.5598 - val_root_mean_squared_error: 0.7482\n",
      "Model training finished.\n",
      "Train RMSE: 0.751\n",
      "Evaluating model performance...\n",
      "Test RMSE: 0.748\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "mse_loss = keras.losses.MeanSquaredError()\n",
    "baseline_model = create_baseline_model()\n",
    "run_experiment(baseline_model, mse_loss, train_dataset, test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e60cce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 5.3 - Actual: 5.0\n",
      "Predicted: 6.2 - Actual: 6.0\n",
      "Predicted: 5.6 - Actual: 5.0\n",
      "Predicted: 5.9 - Actual: 5.0\n",
      "Predicted: 6.1 - Actual: 7.0\n",
      "Predicted: 6.5 - Actual: 8.0\n",
      "Predicted: 6.3 - Actual: 6.0\n",
      "Predicted: 6.1 - Actual: 7.0\n",
      "Predicted: 5.3 - Actual: 6.0\n",
      "Predicted: 6.3 - Actual: 6.0\n"
     ]
    }
   ],
   "source": [
    "sample = 10\n",
    "examples, targets = list(test_dataset.unbatch().shuffle(batch_size * 10).batch(sample))[\n",
    "    0\n",
    "]\n",
    "\n",
    "predicted = baseline_model(examples).numpy()\n",
    "for idx in range(sample):\n",
    "    print(f\"Predicted: {round(float(predicted[idx][0]), 1)} - Actual: {targets[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8733861f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
